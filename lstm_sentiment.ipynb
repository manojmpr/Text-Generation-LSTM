{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network on the [IMDB sentiment classification](https://keras.io/api/datasets/imdb/) task. This is a dataset for binary sentiment classification. 25,000 highly polar movie reviews are provided for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "IMDB sentiment dataset is available in keras.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module tensorflow.python.keras.datasets.imdb:\n",
      "\n",
      "load_data(path='imdb.npz', num_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3, **kwargs)\n",
      "    Loads the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
      "    \n",
      "    This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment\n",
      "    (positive/negative). Reviews have been preprocessed, and each review is\n",
      "    encoded as a list of word indexes (integers).\n",
      "    For convenience, words are indexed by overall frequency in the dataset,\n",
      "    so that for instance the integer \"3\" encodes the 3rd most frequent word in\n",
      "    the data. This allows for quick filtering operations such as:\n",
      "    \"only consider the top 10,000 most\n",
      "    common words, but eliminate the top 20 most common words\".\n",
      "    \n",
      "    As a convention, \"0\" does not stand for a specific word, but instead is used\n",
      "    to encode any unknown word.\n",
      "    \n",
      "    Args:\n",
      "      path: where to cache the data (relative to `~/.keras/dataset`).\n",
      "      num_words: integer or None. Words are\n",
      "          ranked by how often they occur (in the training set) and only\n",
      "          the `num_words` most frequent words are kept. Any less frequent word\n",
      "          will appear as `oov_char` value in the sequence data. If None,\n",
      "          all words are kept. Defaults to None, so all words are kept.\n",
      "      skip_top: skip the top N most frequently occurring words\n",
      "          (which may not be informative). These words will appear as\n",
      "          `oov_char` value in the dataset. Defaults to 0, so no words are\n",
      "          skipped.\n",
      "      maxlen: int or None. Maximum sequence length.\n",
      "          Any longer sequence will be truncated. Defaults to None, which\n",
      "          means no truncation.\n",
      "      seed: int. Seed for reproducible data shuffling.\n",
      "      start_char: int. The start of a sequence will be marked with this\n",
      "          character. Defaults to 1 because 0 is usually the padding character.\n",
      "      oov_char: int. The out-of-vocabulary character.\n",
      "          Words that were cut out because of the `num_words` or\n",
      "          `skip_top` limits will be replaced with this character.\n",
      "      index_from: int. Index actual words with this index and higher.\n",
      "      **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    Returns:\n",
      "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "    \n",
      "    **x_train, x_test**: lists of sequences, which are lists of indexes\n",
      "      (integers). If the num_words argument was specific, the maximum\n",
      "      possible index value is `num_words - 1`. If the `maxlen` argument was\n",
      "      specified, the largest possible sequence length is `maxlen`.\n",
      "    \n",
      "    **y_train, y_test**: lists of integer labels (1 or 0).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: in case `maxlen` is so low\n",
      "          that no input sequence could be kept.\n",
      "    \n",
      "    Note that the 'out of vocabulary' character is only used for\n",
      "    words that were present in the training set but are not included\n",
      "    because they're not making the `num_words` cut here.\n",
      "    Words that were not seen in the training set but are in the test set\n",
      "    have simply been skipped.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imdb.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "# maxlen: cut texts after this number of words (among top max_features most common words)\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Keras has already preprocessed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
       "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
       "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
       "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
       "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
       "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
       "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
       "         16,  145,   95], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321,601\n",
      "Trainable params: 321,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 5s 12ms/step - loss: 0.6181 - accuracy: 0.6380 - val_loss: 0.4687 - val_accuracy: 0.7920\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3769 - accuracy: 0.8412 - val_loss: 0.3951 - val_accuracy: 0.8258\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2799 - accuracy: 0.8873 - val_loss: 0.4211 - val_accuracy: 0.8288\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2078 - accuracy: 0.9229 - val_loss: 0.4748 - val_accuracy: 0.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc631862520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 78.53%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN using the entire sequence instead of the last output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 16)            320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 80, 32)            1568      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 324,129\n",
      "Trainable params: 324,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16, input_length=maxlen))\n",
    "model.add(layers.SimpleRNN(32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 6s 15ms/step - loss: 0.7053 - accuracy: 0.5047 - val_loss: 0.6841 - val_accuracy: 0.5624\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5614 - accuracy: 0.6943 - val_loss: 0.3885 - val_accuracy: 0.8248\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3429 - accuracy: 0.8504 - val_loss: 0.3446 - val_accuracy: 0.8520\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2782 - accuracy: 0.8817 - val_loss: 0.3439 - val_accuracy: 0.8514\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2396 - accuracy: 0.9017 - val_loss: 0.3557 - val_accuracy: 0.8490\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2132 - accuracy: 0.9171 - val_loss: 0.3553 - val_accuracy: 0.8506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc631890190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 84.10%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               74240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 394,369\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 31s 95ms/step - loss: 0.5218 - accuracy: 0.7359 - val_loss: 0.4414 - val_accuracy: 0.8216\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.3354 - accuracy: 0.8609 - val_loss: 0.4834 - val_accuracy: 0.8274\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.2864 - accuracy: 0.8848 - val_loss: 0.3493 - val_accuracy: 0.8480\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 0.2524 - accuracy: 0.8997 - val_loss: 0.7173 - val_accuracy: 0.8122\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2277 - accuracy: 0.9122 - val_loss: 0.3631 - val_accuracy: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc642843550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.64%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         74240     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 525,953\n",
      "Trainable params: 525,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 57s 172ms/step - loss: 0.5238 - accuracy: 0.7363 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 56s 178ms/step - loss: 0.3343 - accuracy: 0.8615 - val_loss: 0.3665 - val_accuracy: 0.8444\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 62s 198ms/step - loss: 0.2802 - accuracy: 0.8866 - val_loss: 0.3633 - val_accuracy: 0.8432\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 62s 198ms/step - loss: 0.2520 - accuracy: 0.9011 - val_loss: 0.3744 - val_accuracy: 0.8422\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 0.2311 - accuracy: 0.9127 - val_loss: 0.3652 - val_accuracy: 0.8458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc618725400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.99%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               148480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 468,737\n",
      "Trainable params: 468,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 47s 140ms/step - loss: 0.5428 - accuracy: 0.7194 - val_loss: 0.6629 - val_accuracy: 0.7516\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.3449 - accuracy: 0.8550 - val_loss: 0.3630 - val_accuracy: 0.8402\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 0.2836 - accuracy: 0.8845 - val_loss: 0.3736 - val_accuracy: 0.8422\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.2400 - accuracy: 0.9061 - val_loss: 0.3622 - val_accuracy: 0.8384\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 0.2187 - accuracy: 0.9160 - val_loss: 0.4789 - val_accuracy: 0.8326\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2007 - accuracy: 0.9272 - val_loss: 0.3811 - val_accuracy: 0.8476\n",
      "Testing set accuracy: 83.64%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
